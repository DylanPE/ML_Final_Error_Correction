{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e7bc49e",
   "metadata": {},
   "source": [
    "# Bert Preposition Correction Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838a0b7d",
   "metadata": {},
   "source": [
    "This is an application of the BERT model towards the task of preposition error correction. Prepositions are a common source of error among L2 speakers. The purpose of this task is to see how wellsuited BERT is towards corrected these sorts of errors. \n",
    "\n",
    "The data for this task is a collection of almost 2 million sentence edits taken from Wikipedia where the sole edit recorded was a change in preposition use. We will use a masking tool to mask the incorrect preposition and see if BERT could correctly generate the expected preposition. \n",
    "\n",
    "Do to all this, we will be using the Huggin Face repo of pretrained BERT classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec902ffe",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-23d64d34b86c>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-23d64d34b86c>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    pip install tensorflow\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#TO DO THIS YOU NEED PYTORCH HUGGIN FACE. USE THESE COMMANDS\n",
    "# pip install pytorch-pretrained-bert pytorch-nlp --user\n",
    "#pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af18734f",
   "metadata": {},
   "source": [
    "1) First Import BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f147e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96974ba",
   "metadata": {},
   "source": [
    "2) Prepare and preprocess data, adding padding etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0d926e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1973824\n",
      "For example , an open-toe sandal will use a different style last to a boot . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#First we pre-preprocess our data. Our data has \n",
    "import re\n",
    "\n",
    "#corrections_list = [ [], [], [], [], [], [], [], [], [], [] ]\n",
    "\n",
    "#Read wiki sentence files into a list. This is so we can iterate through all 2 million sentences \n",
    "#more quickly\n",
    "\n",
    "sent_list = []\n",
    "\n",
    "with open(\"processed_sents.txt\", \"w\") as output:\n",
    "    with open(\"wikiprepdata/sentences.txt\",\"r\") as full_sent_list:\n",
    "        line =  full_sent_list.readline()\n",
    "\n",
    "        while line:\n",
    "            # line.replace('_[A-Z,.!?;:\\']*', '')\n",
    "            line = re.sub(r'_[A-Z,.!?;:\\'\\`]*', '', line)\n",
    "            #output.write(line)\n",
    "            sent_list.append(line)\n",
    "            line =  full_sent_list.readline()\n",
    "\n",
    "#Check this sentence_list works\n",
    "print(len(sent_list))\n",
    "\n",
    "\n",
    "output.close()\n",
    "#Write back into text fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938336a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to make sure POS tags are removed\n",
    "print(sent_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64656afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] For example , an open-toe sandal will use a different style last to a boot . \n",
      " [SEP]\n",
      "1973824\n"
     ]
    }
   ],
   "source": [
    "#Format data specifically for BERT\n",
    "#First add tokens for the beginning \"[CLS] \" and \" [SEP]\" \n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sent_list]\n",
    "print(sentences[0])\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd06bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 231508/231508 [00:00<00:00, 3193508.27B/s]\n"
     ]
    }
   ],
   "source": [
    "#Tokenizer the data we have specifically for BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "print (\"Tokenize the first sentence:\")\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa89352",
   "metadata": {},
   "source": [
    "3) Run untrained BERT model on preposition data to see if it can correctly predict the preposition as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f263d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25961518",
   "metadata": {},
   "source": [
    "4) Add Tensors, finetuning BERT using about 70% of the data for training and 30% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482d5ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b9ebd73",
   "metadata": {},
   "source": [
    "5) Test BERT on Data, tabulate accuracy, precision, and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e3b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run 2-4 epochs of pretraining"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
